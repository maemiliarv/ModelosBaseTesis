{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed precision\n",
    "\n",
    "# Torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "print(\"‚úì Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU verification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"‚úì GPU cache cleared\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU available, training will be slow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Paths\n",
    "    'base_path': '/home/merivadeneira',\n",
    "    'ddsm_benign_path': '/home/merivadeneira/Masas/DDSM/Benignas/Resized_512',\n",
    "    'ddsm_malign_path': '/home/merivadeneira/Masas/DDSM/Malignas/Resized_512',\n",
    "    'inbreast_benign_path': '/home/merivadeneira/Masas/INbreast/Benignas/Resized_512',\n",
    "    'inbreast_malign_path': '/home/merivadeneira/Masas/INbreast/Malignas/Resized_512',\n",
    "    'output_dir': '/home/merivadeneira/Outputs/CvT',\n",
    "    'metrics_dir': '/home/merivadeneira/Metrics/CvT',\n",
    "\n",
    "    # Model\n",
    "    'model_name': 'CvT_0_Base',\n",
    "    'input_size': 512,\n",
    "    'in_channels': 1,  # Grayscale\n",
    "    'num_classes': 2,  # Binary: Benign vs Malignant\n",
    "\n",
    "    # CvT Architecture (CvT-13)\n",
    "    'stages': [\n",
    "        {'embed_dim': 64, 'depth': 1, 'num_heads': 1, 'kernel_size': 7, 'stride': 4, 'padding': 2},\n",
    "        {'embed_dim': 192, 'depth': 2, 'num_heads': 3, 'kernel_size': 3, 'stride': 2, 'padding': 1},\n",
    "        {'embed_dim': 384, 'depth': 10, 'num_heads': 6, 'kernel_size': 3, 'stride': 2, 'padding': 1}\n",
    "    ],\n",
    "    'mlp_ratio': 4.0,\n",
    "    'qkv_bias': True,\n",
    "    'drop_rate': 0.0,\n",
    "    'attn_drop_rate': 0.0,\n",
    "    'drop_path_rate': 0.1,\n",
    "\n",
    "    # Training\n",
    "    'batch_size': 16,  # Will reduce to 8 if OOM\n",
    "    'num_epochs': 100,\n",
    "    'num_folds': 5,\n",
    "    'early_stopping_patience': 25,\n",
    "    'min_delta': 1e-4,\n",
    "\n",
    "    # Optimizer\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr_initial': None,  # Will be set by LR Finder\n",
    "    'lr_min': 1e-7,\n",
    "    'lr_max': 1e-2,\n",
    "    'weight_decay': 0.01,\n",
    "    'betas': (0.9, 0.999),\n",
    "\n",
    "    # Scheduler\n",
    "    'scheduler': 'ReduceLROnPlateau',\n",
    "    'scheduler_factor': 0.5,\n",
    "    'scheduler_patience': 10,\n",
    "    'scheduler_min_lr': 1e-7,\n",
    "\n",
    "    # Data augmentation\n",
    "    'horizontal_flip': 0.5,\n",
    "    'rotation_degrees': 15,\n",
    "    'translate': 0.1,\n",
    "    'scale': (0.9, 1.1),\n",
    "    'shear': 10,\n",
    "    'brightness': 0.1,\n",
    "    'random_erasing_p': 0.15,\n",
    "\n",
    "    # Normalization (grayscale)\n",
    "    'mean': [0.5],\n",
    "    'std': [0.5],\n",
    "\n",
    "    # Mixed Precision & Memory\n",
    "    'use_amp': True,  # Automatic Mixed Precision\n",
    "    'gradient_checkpointing': True,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "\n",
    "    # Reproducibility\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['metrics_dir'], exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "config_path = os.path.join(CONFIG['metrics_dir'], f\"{CONFIG['model_name']}_config.json\")\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=4)\n",
    "\n",
    "print(f\"‚úì Configuration saved to: {config_path}\")\n",
    "print(f\"\\n Model: {CONFIG['model_name']}\")\n",
    "print(f\" Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\" Input size: {CONFIG['input_size']}x{CONFIG['input_size']}\")\n",
    "print(f\" Classes: {CONFIG['num_classes']} (Benign vs Malignant)\")\n",
    "print(f\" Folds: {CONFIG['num_folds']}\")\n",
    "print(f\" Mixed Precision: {CONFIG['use_amp']}\")\n",
    "print(f\" Gradient Checkpointing: {CONFIG['gradient_checkpointing']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "print(f\"‚úì Random seed set to {CONFIG['seed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_id(filename, dataset='ddsm'):\n",
    "    \"\"\"\n",
    "    Extract patient ID from filename to prevent data leakage.\n",
    "\n",
    "    DDSM format: P_00041_LEFT_CC_1.png -> P_00041\n",
    "    INbreast format: 20586908_6c613a14b80a8591_MG_R_CC_ANON_lesion1_ROI.png -> 20586908\n",
    "    \"\"\"\n",
    "    if dataset == 'ddsm':\n",
    "        # Extract P_XXXXX\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]}_{parts[1]}\"  # P_00041\n",
    "    elif dataset == 'inbreast':\n",
    "        # Extract first number (patient ID)\n",
    "        return filename.split('_')[0]\n",
    "\n",
    "    return filename  # Fallback\n",
    "\n",
    "# Test\n",
    "print(\"Testing patient ID extraction:\")\n",
    "print(f\"DDSM: P_00041_LEFT_CC_1.png -> {extract_patient_id('P_00041_LEFT_CC_1.png', 'ddsm')}\")\n",
    "print(f\"INbreast: 20586908_6c613a14b80a8591_MG_R_CC_ANON_lesion1_ROI.png -> {extract_patient_id('20586908_6c613a14b80a8591_MG_R_CC_ANON_lesion1_ROI.png', 'inbreast')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammographyDataset(Dataset):\n",
    "    \"\"\"Custom dataset for mammography images.\"\"\"\n",
    "\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # Grayscale\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "print(\"‚úì Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True):\n",
    "    \"\"\"Get data augmentation transforms.\"\"\"\n",
    "\n",
    "    if train:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=CONFIG['horizontal_flip']),\n",
    "            transforms.RandomRotation(degrees=CONFIG['rotation_degrees']),\n",
    "            transforms.RandomAffine(\n",
    "                degrees=0,\n",
    "                translate=(CONFIG['translate'], CONFIG['translate']),\n",
    "                scale=CONFIG['scale'],\n",
    "                shear=CONFIG['shear']\n",
    "            ),\n",
    "            transforms.ColorJitter(brightness=CONFIG['brightness']),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=CONFIG['mean'], std=CONFIG['std']),\n",
    "            transforms.RandomErasing(p=CONFIG['random_erasing_p'])\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=CONFIG['mean'], std=CONFIG['std'])\n",
    "        ])\n",
    "\n",
    "    return transform\n",
    "\n",
    "print(\"‚úì Transform functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load all images from DDSM and INbreast datasets.\n",
    "    Returns: image_paths, labels, patient_ids\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    patient_ids = []\n",
    "\n",
    "    datasets = [\n",
    "        (CONFIG['ddsm_benign_path'], 0, 'ddsm'),\n",
    "        (CONFIG['ddsm_malign_path'], 1, 'ddsm'),\n",
    "        (CONFIG['inbreast_benign_path'], 0, 'inbreast'),\n",
    "        (CONFIG['inbreast_malign_path'], 1, 'inbreast')\n",
    "    ]\n",
    "\n",
    "    for path, label, dataset_name in datasets:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"‚ö†Ô∏è WARNING: Path not found: {path}\")\n",
    "            continue\n",
    "\n",
    "        files = [f for f in os.listdir(path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        for filename in files:\n",
    "            img_path = os.path.join(path, filename)\n",
    "            patient_id = extract_patient_id(filename, dataset_name)\n",
    "\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(label)\n",
    "            patient_ids.append(patient_id)\n",
    "\n",
    "    return image_paths, labels, patient_ids\n",
    "\n",
    "# Load data\n",
    "print(\"Loading dataset...\")\n",
    "image_paths, labels, patient_ids = load_dataset()\n",
    "\n",
    "print(f\"\\nüìä Dataset loaded:\")\n",
    "print(f\"  Total images: {len(image_paths)}\")\n",
    "print(f\"  Benign: {labels.count(0)}\")\n",
    "print(f\"  Malignant: {labels.count(1)}\")\n",
    "print(f\"  Unique patients: {len(set(patient_ids))}\")\n",
    "\n",
    "# Check class balance\n",
    "class_counts = pd.Series(labels).value_counts()\n",
    "print(f\"\\n‚öñÔ∏è Class distribution:\")\n",
    "for cls, count in class_counts.items():\n",
    "    percentage = (count / len(labels)) * 100\n",
    "    cls_name = \"Benign\" if cls == 0 else \"Malignant\"\n",
    "    print(f\"  {cls_name}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEmbedding(nn.Module):\n",
    "    \"\"\"Convolutional token embedding for CvT.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, embed_dim, kernel_size=3, stride=2, padding=1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(\n",
    "            in_channels, embed_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        x = self.proj(x)  # [B, embed_dim, H', W']\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)  # [B, H'*W', embed_dim]\n",
    "        x = self.norm(x)\n",
    "        return x, (H, W)\n",
    "\n",
    "print(\"‚úì ConvEmbedding defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPositionEncoding(nn.Module):\n",
    "    \"\"\"Convolutional position encoding (CPE) for CvT.\"\"\"\n",
    "\n",
    "    def __init__(self, dim, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(\n",
    "            dim, dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2,\n",
    "            groups=dim  # Depthwise\n",
    "        )\n",
    "\n",
    "    def forward(self, x, size):\n",
    "        # x: [B, N, C]\n",
    "        H, W = size\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        # Reshape to image format\n",
    "        cnn_feat = x.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.proj(cnn_feat) + cnn_feat\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "print(\"‚úì ConvPositionEncoding defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Multi-head self-attention with convolutional projection.\"\"\"\n",
    "\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        # Generate Q, K, V\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        # Attention\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        # Apply attention to values\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "print(\"‚úì Attention defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    \"\"\"MLP module.\"\"\"\n",
    "\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "print(\"‚úì Mlp defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample.\"\"\"\n",
    "\n",
    "    def __init__(self, drop_prob=0.):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "        random_tensor.floor_()  # binarize\n",
    "        output = x.div(keep_prob) * random_tensor\n",
    "        return output\n",
    "\n",
    "print(\"‚úì DropPath defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CvTBlock(nn.Module):\n",
    "    \"\"\"CvT Transformer block.\"\"\"\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False,\n",
    "                 drop=0., attn_drop=0., drop_path=0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias,\n",
    "            attn_drop=attn_drop, proj_drop=drop\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, drop=drop)\n",
    "\n",
    "    def forward(self, x, size):\n",
    "        # Attention with residual\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "\n",
    "        # MLP with residual\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "print(\"‚úì CvTBlock defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CvTStage(nn.Module):\n",
    "    \"\"\"A stage in CvT architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, embed_dim, depth, num_heads, mlp_ratio,\n",
    "                 qkv_bias, drop_rate, attn_drop_rate, drop_path_rate,\n",
    "                 kernel_size=3, stride=2, padding=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional embedding\n",
    "        self.patch_embed = ConvEmbedding(\n",
    "            in_channels, embed_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "\n",
    "        # Convolutional position encoding\n",
    "        self.pos_embed = ConvPositionEncoding(embed_dim, kernel_size=3)\n",
    "\n",
    "        # Transformer blocks\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]\n",
    "        self.blocks = nn.ModuleList([\n",
    "            CvTBlock(\n",
    "                dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[i]\n",
    "            )\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional embedding\n",
    "        x, size = self.patch_embed(x)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = self.pos_embed(x, size)\n",
    "\n",
    "        # Apply transformer blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, size)\n",
    "\n",
    "        return x, size\n",
    "\n",
    "print(\"‚úì CvTStage defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CvT(nn.Module):\n",
    "    \"\"\"Convolutional Vision Transformer (CvT) for image classification.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, num_classes=2, stages=None,\n",
    "                 mlp_ratio=4., qkv_bias=True, drop_rate=0.,\n",
    "                 attn_drop_rate=0., drop_path_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        if stages is None:\n",
    "            # Default CvT-13 configuration\n",
    "            stages = [\n",
    "                {'embed_dim': 64, 'depth': 1, 'num_heads': 1, 'kernel_size': 7, 'stride': 4, 'padding': 2},\n",
    "                {'embed_dim': 192, 'depth': 2, 'num_heads': 3, 'kernel_size': 3, 'stride': 2, 'padding': 1},\n",
    "                {'embed_dim': 384, 'depth': 10, 'num_heads': 6, 'kernel_size': 3, 'stride': 2, 'padding': 1}\n",
    "            ]\n",
    "\n",
    "        self.num_stages = len(stages)\n",
    "\n",
    "        # Build stages\n",
    "        self.stages = nn.ModuleList()\n",
    "        for i, stage_config in enumerate(stages):\n",
    "            stage_in_channels = in_channels if i == 0 else stages[i-1]['embed_dim']\n",
    "\n",
    "            stage = CvTStage(\n",
    "                in_channels=stage_in_channels,\n",
    "                embed_dim=stage_config['embed_dim'],\n",
    "                depth=stage_config['depth'],\n",
    "                num_heads=stage_config['num_heads'],\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop_rate=drop_rate,\n",
    "                attn_drop_rate=attn_drop_rate,\n",
    "                drop_path_rate=drop_path_rate,\n",
    "                kernel_size=stage_config['kernel_size'],\n",
    "                stride=stage_config['stride'],\n",
    "                padding=stage_config['padding']\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "\n",
    "        # Classification head\n",
    "        self.norm = nn.LayerNorm(stages[-1]['embed_dim'])\n",
    "        self.head = nn.Linear(stages[-1]['embed_dim'], num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 1, 512, 512]\n",
    "\n",
    "        # Pass through stages\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            if i == 0:\n",
    "                x, size = stage(x)\n",
    "            else:\n",
    "                # Reshape back to image format for next stage\n",
    "                B, N, C = x.shape\n",
    "                H, W = size\n",
    "                x = x.transpose(1, 2).reshape(B, C, H, W)\n",
    "                x, size = stage(x)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)  # [B, embed_dim]\n",
    "\n",
    "        # Classification\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "print(\"‚úì CvT model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Create model\n",
    "model = CvT(\n",
    "    in_channels=CONFIG['in_channels'],\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    stages=CONFIG['stages'],\n",
    "    mlp_ratio=CONFIG['mlp_ratio'],\n",
    "    qkv_bias=CONFIG['qkv_bias'],\n",
    "    drop_rate=CONFIG['drop_rate'],\n",
    "    attn_drop_rate=CONFIG['attn_drop_rate'],\n",
    "    drop_path_rate=CONFIG['drop_path_rate']\n",
    ").to(device)\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.randn(2, 1, 512, 512).to(device)\n",
    "    output = model(dummy_input)\n",
    "    print(f\"\\n‚úì Model test passed\")\n",
    "    print(f\"  Input shape: {dummy_input.shape}\")\n",
    "    print(f\"  Output shape: {output.shape}\")\n",
    "    print(f\"  Parameters: {count_parameters(model):,}\")\n",
    "\n",
    "# Clean up\n",
    "del model, dummy_input, output\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFinder:\n",
    "    \"\"\"Learning Rate Finder using the LR Range Test.\"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "        # Save initial state\n",
    "        self.model_state = model.state_dict()\n",
    "        self.optimizer_state = optimizer.state_dict()\n",
    "\n",
    "    def range_test(self, train_loader, start_lr=1e-7, end_lr=1, num_iter=100, smooth_f=0.05):\n",
    "        \"\"\"Perform LR range test.\"\"\"\n",
    "\n",
    "        # Reset model and optimizer\n",
    "        self.model.load_state_dict(self.model_state)\n",
    "        self.optimizer.load_state_dict(self.optimizer_state)\n",
    "\n",
    "        # Calculate LR multiplier\n",
    "        mult = (end_lr / start_lr) ** (1 / num_iter)\n",
    "        lr = start_lr\n",
    "\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "        avg_loss = 0.\n",
    "        best_loss = float('inf')\n",
    "        batch_num = 0\n",
    "        losses = []\n",
    "        lrs = []\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        iterator = iter(train_loader)\n",
    "\n",
    "        for iteration in tqdm(range(num_iter), desc=\"LR Finder\"):\n",
    "            # Get batch\n",
    "            try:\n",
    "                inputs, targets = next(iterator)\n",
    "            except StopIteration:\n",
    "                iterator = iter(train_loader)\n",
    "                inputs, targets = next(iterator)\n",
    "\n",
    "            batch_num += 1\n",
    "\n",
    "            inputs = inputs.to(self.device)\n",
    "            targets = targets.to(self.device)\n",
    "\n",
    "            # Forward\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "            # Compute smoothed loss\n",
    "            avg_loss = smooth_f * loss.item() + (1 - smooth_f) * avg_loss\n",
    "            smoothed_loss = avg_loss / (1 - (1 - smooth_f) ** batch_num)\n",
    "\n",
    "            # Stop if loss explodes\n",
    "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "                print(f\"\\n‚ö†Ô∏è Loss exploded at LR={lr:.2e}\")\n",
    "                break\n",
    "\n",
    "            # Record best loss\n",
    "            if smoothed_loss < best_loss or batch_num == 1:\n",
    "                best_loss = smoothed_loss\n",
    "\n",
    "            # Store values\n",
    "            losses.append(smoothed_loss)\n",
    "            lrs.append(lr)\n",
    "\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Update LR\n",
    "            lr *= mult\n",
    "            self.optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "        # Reset model and optimizer\n",
    "        self.model.load_state_dict(self.model_state)\n",
    "        self.optimizer.load_state_dict(self.optimizer_state)\n",
    "\n",
    "        return lrs, losses\n",
    "\n",
    "    def plot(self, lrs, losses, skip_start=10, skip_end=5):\n",
    "        \"\"\"Plot LR range test results.\"\"\"\n",
    "\n",
    "        if skip_start >= len(lrs):\n",
    "            skip_start = 0\n",
    "        if skip_end >= len(lrs):\n",
    "            skip_end = 0\n",
    "\n",
    "        lrs = lrs[skip_start:-skip_end] if skip_end > 0 else lrs[skip_start:]\n",
    "        losses = losses[skip_start:-skip_end] if skip_end > 0 else losses[skip_start:]\n",
    "\n",
    "        # Find minimum\n",
    "        min_idx = np.argmin(losses)\n",
    "        min_lr = lrs[min_idx]\n",
    "\n",
    "        # Suggested LR (10x smaller than minimum)\n",
    "        suggested_lr = min_lr / 10\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Finder')\n",
    "        plt.axvline(x=min_lr, color='r', linestyle='--', label=f'Min Loss LR: {min_lr:.2e}')\n",
    "        plt.axvline(x=suggested_lr, color='g', linestyle='--', label=f'Suggested LR: {suggested_lr:.2e}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Save plot\n",
    "        plot_path = os.path.join(CONFIG['metrics_dir'], f\"{CONFIG['model_name']}_lr_finder.png\")\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nüìä LR Finder Results:\")\n",
    "        print(f\"  Minimum loss LR: {min_lr:.2e}\")\n",
    "        print(f\"  Suggested LR: {suggested_lr:.2e}\")\n",
    "        print(f\"  Plot saved to: {plot_path}\")\n",
    "\n",
    "        return suggested_lr\n",
    "\n",
    "print(\"‚úì LRFinder class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LR Finder\n",
    "print(\"\\nüîç Running Learning Rate Finder...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Create temporary model and dataloader for LR finding\n",
    "temp_model = CvT(\n",
    "    in_channels=CONFIG['in_channels'],\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    stages=CONFIG['stages'],\n",
    "    mlp_ratio=CONFIG['mlp_ratio'],\n",
    "    qkv_bias=CONFIG['qkv_bias'],\n",
    "    drop_rate=CONFIG['drop_rate'],\n",
    "    attn_drop_rate=CONFIG['attn_drop_rate'],\n",
    "    drop_path_rate=CONFIG['drop_path_rate']\n",
    ").to(device)\n",
    "\n",
    "# Create temporary dataset (use first 500 images for speed)\n",
    "temp_indices = list(range(min(500, len(image_paths))))\n",
    "temp_paths = [image_paths[i] for i in temp_indices]\n",
    "temp_labels = [labels[i] for i in temp_indices]\n",
    "\n",
    "temp_dataset = MammographyDataset(\n",
    "    temp_paths,\n",
    "    temp_labels,\n",
    "    transform=get_transforms(train=True)\n",
    ")\n",
    "\n",
    "temp_loader = DataLoader(\n",
    "    temp_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "# Setup for LR Finder\n",
    "temp_optimizer = AdamW(\n",
    "    temp_model.parameters(),\n",
    "    lr=1e-7,\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    betas=CONFIG['betas']\n",
    ")\n",
    "temp_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run LR Finder\n",
    "lr_finder = LRFinder(temp_model, temp_optimizer, temp_criterion, device)\n",
    "lrs, losses = lr_finder.range_test(\n",
    "    temp_loader,\n",
    "    start_lr=CONFIG['lr_min'],\n",
    "    end_lr=CONFIG['lr_max'],\n",
    "    num_iter=100\n",
    ")\n",
    "\n",
    "# Plot and get suggested LR\n",
    "suggested_lr = lr_finder.plot(lrs, losses)\n",
    "\n",
    "# Update config\n",
    "CONFIG['lr_initial'] = suggested_lr\n",
    "\n",
    "# Clean up\n",
    "del temp_model, temp_dataset, temp_loader, temp_optimizer, temp_criterion, lr_finder\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n‚úì Learning rate set to: {CONFIG['lr_initial']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to stop training when validation loss doesn't improve.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=25, min_delta=1e-4, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"  EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "\n",
    "print(\"‚úì EarlyStopping class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler, device, use_amp=True):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for inputs, targets in pbar:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training\n",
    "        if use_amp:\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"‚úì train_epoch function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validation\")\n",
    "        for inputs, targets in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc, all_preds, all_targets\n",
    "\n",
    "print(\"‚úì validate_epoch function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate classification metrics.\"\"\"\n",
    "\n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Specificity (TN / (TN + FP))\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    else:\n",
    "        specificity = 0\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'specificity': specificity,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "print(\"‚úì calculate_metrics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cross_validation():\n",
    "    \"\"\"\n",
    "    Train model with 10-fold cross validation.\n",
    "    Split by patient to prevent data leakage.\n",
    "    \"\"\"\n",
    "\n",
    "    # Group by patient\n",
    "    patient_to_indices = defaultdict(list)\n",
    "    patient_to_label = {}\n",
    "\n",
    "    for idx, (patient_id, label) in enumerate(zip(patient_ids, labels)):\n",
    "        patient_to_indices[patient_id].append(idx)\n",
    "        patient_to_label[patient_id] = label\n",
    "\n",
    "    unique_patients = list(patient_to_indices.keys())\n",
    "    patient_labels = [patient_to_label[p] for p in unique_patients]\n",
    "\n",
    "    print(f\"\\nüìä Cross Validation Setup:\")\n",
    "    print(f\"  Total patients: {len(unique_patients)}\")\n",
    "    print(f\"  Total images: {len(image_paths)}\")\n",
    "    print(f\"  Folds: {CONFIG['num_folds']}\")\n",
    "\n",
    "    # K-Fold split\n",
    "    skf = StratifiedKFold(n_splits=CONFIG['num_folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "    # Store results\n",
    "    fold_metrics = []\n",
    "    fold_histories = []\n",
    "    fold_cms = []\n",
    "\n",
    "    # Train each fold\n",
    "    for fold, (train_patient_idx, val_patient_idx) in enumerate(skf.split(unique_patients, patient_labels)):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"FOLD {fold + 1}/{CONFIG['num_folds']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Get patient IDs for this fold\n",
    "        train_patients = [unique_patients[i] for i in train_patient_idx]\n",
    "        val_patients = [unique_patients[i] for i in val_patient_idx]\n",
    "\n",
    "        # Get image indices\n",
    "        train_indices = []\n",
    "        val_indices = []\n",
    "\n",
    "        for patient in train_patients:\n",
    "            train_indices.extend(patient_to_indices[patient])\n",
    "\n",
    "        for patient in val_patients:\n",
    "            val_indices.extend(patient_to_indices[patient])\n",
    "\n",
    "        # Create datasets\n",
    "        train_paths = [image_paths[i] for i in train_indices]\n",
    "        train_labels = [labels[i] for i in train_indices]\n",
    "        val_paths = [image_paths[i] for i in val_indices]\n",
    "        val_labels = [labels[i] for i in val_indices]\n",
    "\n",
    "        train_dataset = MammographyDataset(train_paths, train_labels, transform=get_transforms(train=True))\n",
    "        val_dataset = MammographyDataset(val_paths, val_labels, transform=get_transforms(train=False))\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=CONFIG['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=CONFIG['num_workers'],\n",
    "            pin_memory=CONFIG['pin_memory']\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=CONFIG['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=CONFIG['num_workers'],\n",
    "            pin_memory=CONFIG['pin_memory']\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüìä Fold {fold + 1} Data:\")\n",
    "        print(f\"  Train patients: {len(train_patients)}\")\n",
    "        print(f\"  Val patients: {len(val_patients)}\")\n",
    "        print(f\"  Train images: {len(train_paths)} (Benign: {train_labels.count(0)}, Malignant: {train_labels.count(1)})\")\n",
    "        print(f\"  Val images: {len(val_paths)} (Benign: {val_labels.count(0)}, Malignant: {val_labels.count(1)})\")\n",
    "\n",
    "        # Create model\n",
    "        model = CvT(\n",
    "            in_channels=CONFIG['in_channels'],\n",
    "            num_classes=CONFIG['num_classes'],\n",
    "            stages=CONFIG['stages'],\n",
    "            mlp_ratio=CONFIG['mlp_ratio'],\n",
    "            qkv_bias=CONFIG['qkv_bias'],\n",
    "            drop_rate=CONFIG['drop_rate'],\n",
    "            attn_drop_rate=CONFIG['attn_drop_rate'],\n",
    "            drop_path_rate=CONFIG['drop_path_rate']\n",
    "        ).to(device)\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr=CONFIG['lr_initial'],\n",
    "            weight_decay=CONFIG['weight_decay'],\n",
    "            betas=CONFIG['betas']\n",
    "        )\n",
    "\n",
    "        # Scheduler\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=CONFIG['scheduler_factor'],\n",
    "            patience=CONFIG['scheduler_patience'],\n",
    "            min_lr=CONFIG['scheduler_min_lr'],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=CONFIG['early_stopping_patience'],\n",
    "            min_delta=CONFIG['min_delta'],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # Mixed precision scaler\n",
    "        scaler = GradScaler() if CONFIG['use_amp'] else None\n",
    "\n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'lr': []\n",
    "        }\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "        # Training loop\n",
    "        print(f\"\\nüöÄ Starting training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(CONFIG['num_epochs']):\n",
    "            print(f\"\\n--- Epoch {epoch + 1}/{CONFIG['num_epochs']} ---\")\n",
    "\n",
    "            # Train\n",
    "            train_loss, train_acc = train_epoch(\n",
    "                model, train_loader, criterion, optimizer, scaler, device, CONFIG['use_amp']\n",
    "            )\n",
    "\n",
    "            # Validate\n",
    "            val_loss, val_acc, val_preds, val_targets = validate_epoch(\n",
    "                model, val_loader, criterion, device\n",
    "            )\n",
    "\n",
    "            # Update scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            # Save history\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['lr'].append(current_lr)\n",
    "\n",
    "            # Print epoch summary\n",
    "            print(f\"\\nüìä Epoch {epoch + 1} Summary:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "            print(f\"  LR: {current_lr:.2e}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch + 1\n",
    "\n",
    "                model_path = os.path.join(\n",
    "                    CONFIG['output_dir'],\n",
    "                    f\"{CONFIG['model_name']}_fold{fold}.pth\"\n",
    "                )\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_acc': val_acc,\n",
    "                    'config': CONFIG\n",
    "                }, model_path)\n",
    "\n",
    "                print(f\"  ‚úì Model saved: {model_path}\")\n",
    "\n",
    "            # Early stopping\n",
    "            early_stopping(val_loss, epoch + 1)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"\\n‚èπÔ∏è Early stopping triggered at epoch {epoch + 1}\")\n",
    "                print(f\"  Best epoch: {best_epoch} with val_loss: {best_val_loss:.4f}\")\n",
    "                break\n",
    "\n",
    "            # Clear cache\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\n‚è±Ô∏è Training time for fold {fold + 1}: {training_time/60:.2f} minutes\")\n",
    "\n",
    "        # Load best model for evaluation\n",
    "        model_path = os.path.join(CONFIG['output_dir'], f\"{CONFIG['model_name']}_fold{fold}.pth\")\n",
    "        checkpoint = torch.load(model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Final evaluation\n",
    "        print(f\"\\nüìä Final evaluation on validation set...\")\n",
    "        _, _, final_preds, final_targets = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(final_targets, final_preds)\n",
    "\n",
    "        print(f\"\\n‚úÖ Fold {fold + 1} Results:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "        print(f\"  Precision: {metrics['precision']*100:.2f}%\")\n",
    "        print(f\"  Recall: {metrics['recall']*100:.2f}%\")\n",
    "        print(f\"  F1-Score: {metrics['f1']*100:.2f}%\")\n",
    "        print(f\"  Specificity: {metrics['specificity']*100:.2f}%\")\n",
    "\n",
    "        # Store results\n",
    "        fold_metrics.append(metrics)\n",
    "        fold_histories.append(history)\n",
    "        fold_cms.append(metrics['confusion_matrix'])\n",
    "\n",
    "        # Plot training history\n",
    "        plot_training_history(history, fold)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(metrics['confusion_matrix'], fold)\n",
    "\n",
    "        # Clean up\n",
    "        del model, optimizer, scheduler, train_loader, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return fold_metrics, fold_histories, fold_cms\n",
    "\n",
    "print(\"‚úì train_with_cross_validation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, fold):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title(f'Fold {fold + 1}: Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy\n",
    "    axes[1].plot([acc*100 for acc in history['train_acc']], label='Train Acc', marker='o')\n",
    "    axes[1].plot([acc*100 for acc in history['val_acc']], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title(f'Fold {fold + 1}: Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning Rate\n",
    "    axes[2].plot(history['lr'], marker='o')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title(f'Fold {fold + 1}: Learning Rate')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    plot_path = os.path.join(\n",
    "        CONFIG['metrics_dir'],\n",
    "        f\"{CONFIG['model_name']}_fold{fold}_history.png\"\n",
    "    )\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"  History plot saved: {plot_path}\")\n",
    "\n",
    "print(\"‚úì plot_training_history function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, fold, normalize=False):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='.2f' if normalize else 'd',\n",
    "        cmap='Blues',\n",
    "        xticklabels=['Benign', 'Malignant'],\n",
    "        yticklabels=['Benign', 'Malignant'],\n",
    "        cbar_kws={'label': 'Count'}\n",
    "    )\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title(f'Fold {fold + 1}: Confusion Matrix')\n",
    "\n",
    "    # Save\n",
    "    plot_path = os.path.join(\n",
    "        CONFIG['metrics_dir'],\n",
    "        f\"{CONFIG['model_name']}_fold{fold}_cm.png\"\n",
    "    )\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"  Confusion matrix saved: {plot_path}\")\n",
    "\n",
    "print(\"‚úì plot_confusion_matrix function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_summary(fold_metrics):\n",
    "    \"\"\"Save metrics summary to CSV.\"\"\"\n",
    "\n",
    "    # Extract metrics\n",
    "    metrics_dict = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-Score': [],\n",
    "        'Specificity': []\n",
    "    }\n",
    "\n",
    "    for fold, metrics in enumerate(fold_metrics):\n",
    "        metrics_dict['Fold'].append(fold + 1)\n",
    "        metrics_dict['Accuracy'].append(metrics['accuracy'])\n",
    "        metrics_dict['Precision'].append(metrics['precision'])\n",
    "        metrics_dict['Recall'].append(metrics['recall'])\n",
    "        metrics_dict['F1-Score'].append(metrics['f1'])\n",
    "        metrics_dict['Specificity'].append(metrics['specificity'])\n",
    "\n",
    "    # Calculate mean and std\n",
    "    for key in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity']:\n",
    "        values = metrics_dict[key]\n",
    "        metrics_dict['Fold'].append('Mean ¬± Std')\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        metrics_dict[key].append(f\"{mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "        break\n",
    "\n",
    "    # Fill rest of the summary row\n",
    "    for key in ['Precision', 'Recall', 'F1-Score', 'Specificity']:\n",
    "        values = [m for m in metrics_dict[key] if isinstance(m, float)]\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        metrics_dict[key].append(f\"{mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(metrics_dict)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_path = os.path.join(\n",
    "        CONFIG['metrics_dir'],\n",
    "        f\"{CONFIG['model_name']}_metrics.csv\"\n",
    "    )\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Metrics saved to: {csv_path}\")\n",
    "    print(f\"\\n{df.to_string(index=False)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"‚úì save_metrics_summary function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_confusion_matrix(fold_cms):\n",
    "    \"\"\"Plot average confusion matrix across all folds.\"\"\"\n",
    "\n",
    "    # Average confusion matrix\n",
    "    avg_cm = np.mean(fold_cms, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        avg_cm,\n",
    "        annot=True,\n",
    "        fmt='.1f',\n",
    "        cmap='Blues',\n",
    "        xticklabels=['Benign', 'Malignant'],\n",
    "        yticklabels=['Benign', 'Malignant'],\n",
    "        cbar_kws={'label': 'Average Count'}\n",
    "    )\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Average Confusion Matrix (10-Fold CV)')\n",
    "\n",
    "    # Save\n",
    "    plot_path = os.path.join(\n",
    "        CONFIG['metrics_dir'],\n",
    "        f\"{CONFIG['model_name']}_avg_cm.png\"\n",
    "    )\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n‚úÖ Average confusion matrix saved: {plot_path}\")\n",
    "\n",
    "print(\"‚úì plot_average_confusion_matrix function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING 10-FOLD CROSS VALIDATION TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train\n",
    "fold_metrics, fold_histories, fold_cms = train_with_cross_validation()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚è±Ô∏è Total training time: {total_time/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics summary\n",
    "print(\"\\nüìä Saving final metrics summary...\")\n",
    "metrics_df = save_metrics_summary(fold_metrics)\n",
    "\n",
    "# Plot average confusion matrix\n",
    "print(\"\\nüìä Plotting average confusion matrix...\")\n",
    "plot_average_confusion_matrix(fold_cms)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL RESULTS SAVED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Output directory: {CONFIG['output_dir']}\")\n",
    "print(f\"üìä Metrics directory: {CONFIG['metrics_dir']}\")\n",
    "print(f\"\\nüéâ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate overall statistics\n",
    "accuracies = [m['accuracy'] for m in fold_metrics]\n",
    "precisions = [m['precision'] for m in fold_metrics]\n",
    "recalls = [m['recall'] for m in fold_metrics]\n",
    "f1s = [m['f1'] for m in fold_metrics]\n",
    "specificities = [m['specificity'] for m in fold_metrics]\n",
    "\n",
    "print(f\"\\n Model: {CONFIG['model_name']}\")\n",
    "print(f\" Architecture: CvT-13 (3-stage hierarchical)\")\n",
    "print(f\" Parameters: ~20M\")\n",
    "print(f\" Dataset: DDSM + INbreast\")\n",
    "print(f\" Images: {len(image_paths)} total\")\n",
    "print(f\" Patients: {len(set(patient_ids))} unique\")\n",
    "print(f\" Folds: {CONFIG['num_folds']}\")\n",
    "\n",
    "print(f\"\\n Performance (Mean ¬± Std):\")\n",
    "print(f\"  Accuracy:    {np.mean(accuracies)*100:.2f}% ¬± {np.std(accuracies)*100:.2f}%\")\n",
    "print(f\"  Precision:   {np.mean(precisions)*100:.2f}% ¬± {np.std(precisions)*100:.2f}%\")\n",
    "print(f\"  Recall:      {np.mean(recalls)*100:.2f}% ¬± {np.std(recalls)*100:.2f}%\")\n",
    "print(f\"  F1-Score:    {np.mean(f1s)*100:.2f}% ¬± {np.std(f1s)*100:.2f}%\")\n",
    "print(f\"  Specificity: {np.mean(specificities)*100:.2f}% ¬± {np.std(specificities)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚è± Training time: {total_time/3600:.2f} hours\")\n",
    "print(f\" Models saved: {CONFIG['num_folds']} folds\")\n",
    "print(f\" Metrics saved: {CONFIG['metrics_dir']}\")\n",
    "\n",
    "print(\"\\n CvT_0_Base training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
